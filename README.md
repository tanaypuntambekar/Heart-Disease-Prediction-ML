# Heart-Disease-Prediction-ML
Predicting and diagnosing heart disease is one of the major challenges in the medical industry as it depends on several factors including physical examination and various symptoms and signs present in the patient. Heart disease is considered as one of the deadliest disease in the world for human life due to the heart's inability to push the required amount of blood to other body organs to perform the regular functions in the human body. There are several factors affecting heart disease include but not limited cholesterol levels in the body, smoking habits and obesity, family history of diseases, blood pressure, work environment and others. 

Today, ML Algorithms play an essential and accurate role in heart disease prediction. Rapid advances in technology allow Machine Language to integrate with Big Data tools to manage the exponentially growing unstructured data that includes medical data for patients around the world. Heart disease can be predicted based on different symptoms like age, gender, heart rate etc. which in turn reduces the death rate for heart patients. In this report we are going to use machine learning algorithms and Python language to do that.​

In the following analysis will compare between 4 different Classification models 
Logistic Regression, KNN, SVM and XGBoost in terms of predicting the Heart Disease. 

Where I am going to use the following techniques to help me in developing robust models: ​
Standard scaling, cross-validation method, Grid Search, metric measurements such accuracy, precision,  F1 Score etc.​

In terms of simplicity, we can say Logistic Regression provided high predictive results and at the same time it is the simplest and fastest Model in terms of parameters and training but if we look to other models like KNN it is providing the best results, but it is slower in terms of prediction process because it requires to calculate the distance between all the points in the dataset to classify every single point.​
​

XGBoost performance was very good as well but in contrast of KNN it takes longer time in the training process since we used grid search technique to search about best fitting parameters, so at the end it is a tradeoff if we have bigger dataset then the performance will be higher with such models, but the training process will take a longer time.​
